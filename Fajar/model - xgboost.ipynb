{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "mingw_path = 'C:\\\\mingw-w64\\\\x86_64-6.3.0-posix-seh-rt_v5-rev2\\\\mingw64\\\\bin'\n",
    "os.environ['PATH'] = mingw_path + ';' + os.environ['PATH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import RandomizedSearchCV, cross_val_score, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74067"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv', encoding=\"latin-1\")\n",
    "test = pd.read_csv('test.csv', encoding=\"latin-1\")\n",
    "num_train = train.shape[0]\n",
    "num_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'id', 'product_title', 'product_uid', 'relevance',\n",
       "       'search_term', 'product_description', 'product_colour', 'brand',\n",
       "       'product_weight', 'product_depth', 'product_height', 'product_width',\n",
       "       'Bullet01', 'Bullet02', 'Bullet03', 'Bullet04', 'Bullet05',\n",
       "       'num_words_query', 'num_words_title', 'num_words_brand',\n",
       "       'num_words_colour', 'num_words_weight', 'num_words_height',\n",
       "       'num_words_depth', 'num_words_width', 'query_in_title',\n",
       "       'common_words_query_and_title', 'query_last_word_in_title',\n",
       "       'title_seq_match_score', 'title_levenshtein_ratio',\n",
       "       'title_Jaccard_dist_norm', 'ratio_title', 'query_in_description',\n",
       "       'common_words_query_and_desc', 'query_last_word_in_desc',\n",
       "       'desc_sequence_match_score', 'desc_levenshtein_ratio',\n",
       "       'desc_Jaccard_dist_norm', 'ratio_description', 'query_in_brand',\n",
       "       'common_words_query_and_brand', 'brand_sequence_match_score',\n",
       "       'brand_levenshtein_ratio', 'brand_Jaccard_dist_norm', 'ratio_brand',\n",
       "       'query_in_colour', 'common_words_query_and_colour',\n",
       "       'query_first_word_in_colour', 'colour_sequence_match_score',\n",
       "       'colour_levenshtein_ratio', 'colour_Jaccard_dist_norm', 'ratio_colour',\n",
       "       'common_words_query_and_size', 'query_last_word_in_size',\n",
       "       'size_sequence_match_score', 'size_levenshtein_ratio',\n",
       "       'size_Jaccard_dist_norm', 'ratio_size', 'query_in_bullets',\n",
       "       'common_words_query_and_bullets', 'bullets_sequence_match_score',\n",
       "       'bullets_levenshtein_ratio', 'bullets_Jaccard_dist_norm',\n",
       "       'ratio_bullets'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = pd.read_csv('ready.csv')\n",
    "features.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = features.drop(['Unnamed: 0', 'product_title', 'product_uid', \n",
    "       'search_term', 'product_description', 'product_colour', 'brand',\n",
    "       'product_weight', 'product_depth', 'product_height', 'product_width',\n",
    "       'Bullet01', 'Bullet02', 'Bullet03', 'Bullet04', 'Bullet05',],axis=1)\n",
    "features = features.fillna(0)\n",
    "df_train = features.iloc[:num_train]\n",
    "df_test = features.iloc[num_train:]\n",
    "id_test = df_test['id']\n",
    "y_train = df_train['relevance']\n",
    "x_train = df_train.drop(['id','relevance'],axis=1)\n",
    "x_test = df_test.drop(['id','relevance'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74067 74067 166693 240760 166693\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train), len(y_train), len(x_test), len(features), len(id_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([  0.89962133,  18.68466194,  12.4118197 ,   6.94693756,\n",
       "         18.1895837 ,  17.52845399,  25.60686556,  10.78867722,\n",
       "         13.93283709,  11.37902196,  13.5779504 ,  11.11828907,\n",
       "         12.86379735,  18.89875778,  17.61656721,  17.42851154,\n",
       "         22.90115746,  11.18425528,  14.06277466,   9.21448859,\n",
       "          7.59294955,   9.37884164,  30.14523419,  14.23145111,\n",
       "          6.32101885,   0.89597297,   9.56112806,  16.22005121,\n",
       "          6.41970658,  17.70391448,  35.75126664,  21.31314445,\n",
       "          1.38791068,   1.11761864,  11.81033039,  11.77815032,\n",
       "          9.33592804,   2.45073247,   1.07344858,   7.78778108,\n",
       "          0.91466951,  11.8485597 ,  15.12035004,   0.98120817,\n",
       "          0.82673152,   2.45225135,   3.15761654,  10.90143005,\n",
       "          5.42488321,   6.5989635 ]),\n",
       " 'mean_score_time': array([ 0.06838139,  0.36909691,  0.23517179,  0.18579729,  0.20848012,\n",
       "         0.23416607,  0.40212258,  0.24332388,  0.22410671,  0.20868087,\n",
       "         0.26930014,  0.22471682,  0.17015235,  0.57367977,  0.48917063,\n",
       "         0.61195723,  0.33385054,  0.34746695,  0.33989223,  0.16084019,\n",
       "         0.16095471,  0.09885883,  0.91965254,  0.18905036,  0.15842994,\n",
       "         0.06037331,  0.13943084,  0.4659965 ,  0.09255854,  0.22393322,\n",
       "         0.72188393,  0.30497018,  0.06572954,  0.06114475,  0.21415933,\n",
       "         0.20269084,  0.14062619,  0.08942167,  0.0468773 ,  0.15625246,\n",
       "         0.05729342,  0.15625087,  0.29363259,  0.06249921,  0.06254339,\n",
       "         0.08864657,  0.0880758 ,  0.19978476,  0.2095534 ,  0.08550437]),\n",
       " 'mean_test_score': array([-0.23714053, -0.23196891, -0.22982188, -0.23617284, -0.23452831,\n",
       "        -0.71907447, -0.23549889, -0.22777978, -0.2269722 , -0.23617065,\n",
       "        -0.22742151, -0.23532436, -0.22652536, -0.23010207, -0.23631132,\n",
       "        -0.23596608, -0.23517721, -0.22615385, -0.22851015, -0.22651646,\n",
       "        -0.72741464, -0.22807342, -0.2435999 , -0.22642765, -0.23341782,\n",
       "        -0.2366782 , -0.71358916, -0.23209468, -0.22694954, -0.22931271,\n",
       "        -0.23905654, -0.29413505, -0.23941783, -0.72597685, -0.22929181,\n",
       "        -0.22805796, -0.71305572, -0.2317915 , -0.25055642, -0.23172839,\n",
       "        -0.24158157, -0.71641812, -0.2281677 , -0.23828241, -0.23844757,\n",
       "        -0.22973326, -0.2328895 , -0.23194073, -0.25778115, -0.22698892]),\n",
       " 'mean_train_score': array([-0.22831225, -0.10522872, -0.13221103, -0.21333041, -0.11994616,\n",
       "        -0.68923224, -0.13360291, -0.14830018, -0.11635945, -0.14804615,\n",
       "        -0.16167513, -0.16672066, -0.15183881, -0.11330126, -0.1239751 ,\n",
       "        -0.13325872, -0.16911796, -0.12163917, -0.11476646, -0.14678425,\n",
       "        -0.71498517, -0.20923757, -0.06681617, -0.14862847, -0.18011349,\n",
       "        -0.22767288, -0.70159849, -0.09812159, -0.2070481 , -0.1417388 ,\n",
       "        -0.02571549, -0.24028486, -0.23075696, -0.7243298 , -0.15776826,\n",
       "        -0.16320516, -0.69526356, -0.21140322, -0.24286374, -0.16711437,\n",
       "        -0.23303208, -0.69212804, -0.11574059, -0.22942129, -0.22956486,\n",
       "        -0.21655842, -0.20960909, -0.16887894, -0.16391604, -0.20469283]),\n",
       " 'param_colsample_bylevel': masked_array(data = [0.7777777777777778 1.0 1.0 0.7777777777777778 1.0 1.0 0.6666666666666666\n",
       "  0.5555555555555556 0.6666666666666666 0.8333333333333333\n",
       "  0.7222222222222222 0.6111111111111112 0.9444444444444444\n",
       "  0.5555555555555556 0.7777777777777778 0.7222222222222222\n",
       "  0.6666666666666666 0.5555555555555556 0.5 0.7222222222222222\n",
       "  0.8888888888888888 0.9444444444444444 0.8333333333333333\n",
       "  0.7222222222222222 0.5555555555555556 0.5555555555555556\n",
       "  0.7222222222222222 0.6111111111111112 0.6111111111111112\n",
       "  0.9444444444444444 0.7222222222222222 0.9444444444444444\n",
       "  0.5555555555555556 1.0 0.7222222222222222 0.7222222222222222\n",
       "  0.6111111111111112 0.7777777777777778 0.6666666666666666\n",
       "  0.9444444444444444 0.6111111111111112 0.6111111111111112\n",
       "  0.9444444444444444 0.9444444444444444 0.6111111111111112\n",
       "  0.6111111111111112 1.0 0.6666666666666666 0.6666666666666666 1.0],\n",
       "              mask = [False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False],\n",
       "        fill_value = ?),\n",
       " 'param_colsample_bytree': masked_array(data = [0.5555555555555556 0.6666666666666666 0.6111111111111112 0.5\n",
       "  0.9444444444444444 0.5555555555555556 0.9444444444444444\n",
       "  0.8333333333333333 0.6666666666666666 0.8888888888888888\n",
       "  0.8333333333333333 0.7222222222222222 0.7222222222222222\n",
       "  0.7222222222222222 0.8333333333333333 0.6111111111111112\n",
       "  0.7777777777777778 0.5555555555555556 0.7222222222222222\n",
       "  0.5555555555555556 0.7222222222222222 0.8888888888888888 1.0\n",
       "  0.6111111111111112 0.9444444444444444 0.7777777777777778\n",
       "  0.6666666666666666 0.5 0.8888888888888888 0.7777777777777778 1.0\n",
       "  0.7777777777777778 0.8888888888888888 0.7777777777777778\n",
       "  0.8888888888888888 0.8333333333333333 0.8888888888888888\n",
       "  0.6111111111111112 0.8333333333333333 0.6111111111111112\n",
       "  0.8333333333333333 0.8888888888888888 0.5 0.5 0.6111111111111112\n",
       "  0.5555555555555556 0.6666666666666666 1.0 0.5 0.6666666666666666],\n",
       "              mask = [False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False],\n",
       "        fill_value = ?),\n",
       " 'param_gamma': masked_array(data = [0.8888888888888888 0.1111111111111111 0.2222222222222222 1.0 0.0\n",
       "  0.1111111111111111 0.3333333333333333 0.3333333333333333\n",
       "  0.4444444444444444 0.1111111111111111 0.6666666666666666\n",
       "  0.8888888888888888 0.0 0.8888888888888888 0.0 0.2222222222222222\n",
       "  0.5555555555555556 0.3333333333333333 0.1111111111111111\n",
       "  0.6666666666666666 0.5555555555555556 1.0 0.0 1.0 0.7777777777777777\n",
       "  0.7777777777777777 0.0 0.5555555555555556 0.8888888888888888 1.0 0.0\n",
       "  0.7777777777777777 0.1111111111111111 0.5555555555555556\n",
       "  0.7777777777777777 1.0 0.3333333333333333 0.5555555555555556 1.0\n",
       "  0.5555555555555556 0.2222222222222222 0.1111111111111111\n",
       "  0.2222222222222222 0.2222222222222222 0.0 0.7777777777777777\n",
       "  0.5555555555555556 1.0 0.0 0.3333333333333333],\n",
       "              mask = [False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False],\n",
       "        fill_value = ?),\n",
       " 'param_learning_rate': masked_array(data = [0.07 0.06000000000000001 0.09000000000000001 0.030000000000000006\n",
       "  0.09000000000000001 0.01 0.030000000000000006 0.05000000000000001 0.07\n",
       "  0.07 0.07 0.09000000000000001 0.06000000000000001 0.04000000000000001\n",
       "  0.04000000000000001 0.030000000000000006 0.030000000000000006\n",
       "  0.06000000000000001 0.04000000000000001 0.09000000000000001 0.01\n",
       "  0.04000000000000001 0.030000000000000006 0.09000000000000001\n",
       "  0.09000000000000001 0.08 0.01 0.09000000000000001 0.05000000000000001\n",
       "  0.06000000000000001 0.07 0.020000000000000004 0.05000000000000001 0.01\n",
       "  0.07 0.09000000000000001 0.01 0.09000000000000001 0.030000000000000006\n",
       "  0.09000000000000001 0.04000000000000001 0.01 0.04000000000000001\n",
       "  0.06000000000000001 0.06000000000000001 0.04000000000000001\n",
       "  0.09000000000000001 0.06000000000000001 0.09000000000000001\n",
       "  0.06000000000000001],\n",
       "              mask = [False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False],\n",
       "        fill_value = ?),\n",
       " 'param_max_depth': masked_array(data = [1 21 11 11 11 26 21 16 16 16 11 21 11 26 26 16 21 16 21 11 16 6 21 16 11 1\n",
       "  26 26 6 16 26 21 1 1 11 11 11 6 1 11 1 26 21 1 1 6 6 16 16 6],\n",
       "              mask = [False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False],\n",
       "        fill_value = ?),\n",
       " 'param_min_child_weight': masked_array(data = [4 7 1 1 3 5 5 5 7 8 1 5 4 2 4 4 3 6 6 2 1 4 1 4 7 6 9 1 2 5 1 4 5 2 1 3 4\n",
       "  7 4 1 7 7 8 3 6 4 1 2 5 9],\n",
       "              mask = [False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False],\n",
       "        fill_value = ?),\n",
       " 'param_reg_alpha': masked_array(data = [0.6666666666666666 0.8888888888888888 0.6666666666666666\n",
       "  0.8888888888888888 0.2222222222222222 0.2222222222222222\n",
       "  0.7777777777777777 0.8888888888888888 0.8888888888888888\n",
       "  0.5555555555555556 0.8888888888888888 1.0 1.0 0.0 0.0 0.0\n",
       "  0.7777777777777777 0.8888888888888888 0.6666666666666666\n",
       "  0.5555555555555556 0.2222222222222222 0.2222222222222222 0.0 1.0\n",
       "  0.5555555555555556 0.8888888888888888 1.0 0.7777777777777777\n",
       "  0.6666666666666666 0.1111111111111111 0.7777777777777777\n",
       "  0.3333333333333333 0.2222222222222222 0.2222222222222222\n",
       "  0.2222222222222222 0.7777777777777777 0.4444444444444444\n",
       "  0.6666666666666666 0.3333333333333333 1.0 0.6666666666666666\n",
       "  0.5555555555555556 0.4444444444444444 0.2222222222222222\n",
       "  0.3333333333333333 0.8888888888888888 0.2222222222222222\n",
       "  0.4444444444444444 0.2222222222222222 0.4444444444444444],\n",
       "              mask = [False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False],\n",
       "        fill_value = ?),\n",
       " 'param_reg_lambda': masked_array(data = [1.0 0.01 1.0 0.12 0.23 1.0 0.12 0.56 0.01 0.89 0.56 0.56 0.78 0.12 0.89\n",
       "  0.23 0.78 0.56 0.01 0.67 0.78 1.0 0.12 0.56 1.0 0.12 0.45 0.56 1.0 0.34\n",
       "  0.01 1.0 0.45 0.23 0.45 0.23 0.45 0.67 0.45 0.78 0.89 0.23 0.45 0.34 1.0\n",
       "  0.45 0.12 0.45 0.23 0.89],\n",
       "              mask = [False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False],\n",
       "        fill_value = ?),\n",
       " 'param_subsample': masked_array(data = [0.1 0.4 0.6 0.30000000000000004 0.4 0.7000000000000001 0.8 0.4 1.0 0.2 0.6\n",
       "  0.2 0.7000000000000001 0.4 0.2 0.4 0.5 1.0 0.6 1.0 0.1 1.0 0.4 1.0 0.2 0.1\n",
       "  0.7000000000000001 0.6 1.0 0.4 0.7000000000000001 0.5 0.4 0.1 0.4 0.6 0.6\n",
       "  0.1 0.30000000000000004 0.30000000000000004 0.2 0.5 0.6\n",
       "  0.30000000000000004 0.2 0.2 0.1 0.2 0.1 0.7000000000000001],\n",
       "              mask = [False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False],\n",
       "        fill_value = ?),\n",
       " 'params': ({'colsample_bylevel': 0.7777777777777778,\n",
       "   'colsample_bytree': 0.5555555555555556,\n",
       "   'gamma': 0.8888888888888888,\n",
       "   'learning_rate': 0.07,\n",
       "   'max_depth': 1,\n",
       "   'min_child_weight': 4,\n",
       "   'reg_alpha': 0.6666666666666666,\n",
       "   'reg_lambda': 1.0,\n",
       "   'subsample': 0.1},\n",
       "  {'colsample_bylevel': 1.0,\n",
       "   'colsample_bytree': 0.6666666666666666,\n",
       "   'gamma': 0.1111111111111111,\n",
       "   'learning_rate': 0.06000000000000001,\n",
       "   'max_depth': 21,\n",
       "   'min_child_weight': 7,\n",
       "   'reg_alpha': 0.8888888888888888,\n",
       "   'reg_lambda': 0.01,\n",
       "   'subsample': 0.4},\n",
       "  {'colsample_bylevel': 1.0,\n",
       "   'colsample_bytree': 0.6111111111111112,\n",
       "   'gamma': 0.2222222222222222,\n",
       "   'learning_rate': 0.09000000000000001,\n",
       "   'max_depth': 11,\n",
       "   'min_child_weight': 1,\n",
       "   'reg_alpha': 0.6666666666666666,\n",
       "   'reg_lambda': 1.0,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bylevel': 0.7777777777777778,\n",
       "   'colsample_bytree': 0.5,\n",
       "   'gamma': 1.0,\n",
       "   'learning_rate': 0.030000000000000006,\n",
       "   'max_depth': 11,\n",
       "   'min_child_weight': 1,\n",
       "   'reg_alpha': 0.8888888888888888,\n",
       "   'reg_lambda': 0.12,\n",
       "   'subsample': 0.30000000000000004},\n",
       "  {'colsample_bylevel': 1.0,\n",
       "   'colsample_bytree': 0.9444444444444444,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.09000000000000001,\n",
       "   'max_depth': 11,\n",
       "   'min_child_weight': 3,\n",
       "   'reg_alpha': 0.2222222222222222,\n",
       "   'reg_lambda': 0.23,\n",
       "   'subsample': 0.4},\n",
       "  {'colsample_bylevel': 1.0,\n",
       "   'colsample_bytree': 0.5555555555555556,\n",
       "   'gamma': 0.1111111111111111,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 26,\n",
       "   'min_child_weight': 5,\n",
       "   'reg_alpha': 0.2222222222222222,\n",
       "   'reg_lambda': 1.0,\n",
       "   'subsample': 0.7000000000000001},\n",
       "  {'colsample_bylevel': 0.6666666666666666,\n",
       "   'colsample_bytree': 0.9444444444444444,\n",
       "   'gamma': 0.3333333333333333,\n",
       "   'learning_rate': 0.030000000000000006,\n",
       "   'max_depth': 21,\n",
       "   'min_child_weight': 5,\n",
       "   'reg_alpha': 0.7777777777777777,\n",
       "   'reg_lambda': 0.12,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bylevel': 0.5555555555555556,\n",
       "   'colsample_bytree': 0.8333333333333333,\n",
       "   'gamma': 0.3333333333333333,\n",
       "   'learning_rate': 0.05000000000000001,\n",
       "   'max_depth': 16,\n",
       "   'min_child_weight': 5,\n",
       "   'reg_alpha': 0.8888888888888888,\n",
       "   'reg_lambda': 0.56,\n",
       "   'subsample': 0.4},\n",
       "  {'colsample_bylevel': 0.6666666666666666,\n",
       "   'colsample_bytree': 0.6666666666666666,\n",
       "   'gamma': 0.4444444444444444,\n",
       "   'learning_rate': 0.07,\n",
       "   'max_depth': 16,\n",
       "   'min_child_weight': 7,\n",
       "   'reg_alpha': 0.8888888888888888,\n",
       "   'reg_lambda': 0.01,\n",
       "   'subsample': 1.0},\n",
       "  {'colsample_bylevel': 0.8333333333333333,\n",
       "   'colsample_bytree': 0.8888888888888888,\n",
       "   'gamma': 0.1111111111111111,\n",
       "   'learning_rate': 0.07,\n",
       "   'max_depth': 16,\n",
       "   'min_child_weight': 8,\n",
       "   'reg_alpha': 0.5555555555555556,\n",
       "   'reg_lambda': 0.89,\n",
       "   'subsample': 0.2},\n",
       "  {'colsample_bylevel': 0.7222222222222222,\n",
       "   'colsample_bytree': 0.8333333333333333,\n",
       "   'gamma': 0.6666666666666666,\n",
       "   'learning_rate': 0.07,\n",
       "   'max_depth': 11,\n",
       "   'min_child_weight': 1,\n",
       "   'reg_alpha': 0.8888888888888888,\n",
       "   'reg_lambda': 0.56,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bylevel': 0.6111111111111112,\n",
       "   'colsample_bytree': 0.7222222222222222,\n",
       "   'gamma': 0.8888888888888888,\n",
       "   'learning_rate': 0.09000000000000001,\n",
       "   'max_depth': 21,\n",
       "   'min_child_weight': 5,\n",
       "   'reg_alpha': 1.0,\n",
       "   'reg_lambda': 0.56,\n",
       "   'subsample': 0.2},\n",
       "  {'colsample_bylevel': 0.9444444444444444,\n",
       "   'colsample_bytree': 0.7222222222222222,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.06000000000000001,\n",
       "   'max_depth': 11,\n",
       "   'min_child_weight': 4,\n",
       "   'reg_alpha': 1.0,\n",
       "   'reg_lambda': 0.78,\n",
       "   'subsample': 0.7000000000000001},\n",
       "  {'colsample_bylevel': 0.5555555555555556,\n",
       "   'colsample_bytree': 0.7222222222222222,\n",
       "   'gamma': 0.8888888888888888,\n",
       "   'learning_rate': 0.04000000000000001,\n",
       "   'max_depth': 26,\n",
       "   'min_child_weight': 2,\n",
       "   'reg_alpha': 0.0,\n",
       "   'reg_lambda': 0.12,\n",
       "   'subsample': 0.4},\n",
       "  {'colsample_bylevel': 0.7777777777777778,\n",
       "   'colsample_bytree': 0.8333333333333333,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.04000000000000001,\n",
       "   'max_depth': 26,\n",
       "   'min_child_weight': 4,\n",
       "   'reg_alpha': 0.0,\n",
       "   'reg_lambda': 0.89,\n",
       "   'subsample': 0.2},\n",
       "  {'colsample_bylevel': 0.7222222222222222,\n",
       "   'colsample_bytree': 0.6111111111111112,\n",
       "   'gamma': 0.2222222222222222,\n",
       "   'learning_rate': 0.030000000000000006,\n",
       "   'max_depth': 16,\n",
       "   'min_child_weight': 4,\n",
       "   'reg_alpha': 0.0,\n",
       "   'reg_lambda': 0.23,\n",
       "   'subsample': 0.4},\n",
       "  {'colsample_bylevel': 0.6666666666666666,\n",
       "   'colsample_bytree': 0.7777777777777778,\n",
       "   'gamma': 0.5555555555555556,\n",
       "   'learning_rate': 0.030000000000000006,\n",
       "   'max_depth': 21,\n",
       "   'min_child_weight': 3,\n",
       "   'reg_alpha': 0.7777777777777777,\n",
       "   'reg_lambda': 0.78,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bylevel': 0.5555555555555556,\n",
       "   'colsample_bytree': 0.5555555555555556,\n",
       "   'gamma': 0.3333333333333333,\n",
       "   'learning_rate': 0.06000000000000001,\n",
       "   'max_depth': 16,\n",
       "   'min_child_weight': 6,\n",
       "   'reg_alpha': 0.8888888888888888,\n",
       "   'reg_lambda': 0.56,\n",
       "   'subsample': 1.0},\n",
       "  {'colsample_bylevel': 0.5,\n",
       "   'colsample_bytree': 0.7222222222222222,\n",
       "   'gamma': 0.1111111111111111,\n",
       "   'learning_rate': 0.04000000000000001,\n",
       "   'max_depth': 21,\n",
       "   'min_child_weight': 6,\n",
       "   'reg_alpha': 0.6666666666666666,\n",
       "   'reg_lambda': 0.01,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bylevel': 0.7222222222222222,\n",
       "   'colsample_bytree': 0.5555555555555556,\n",
       "   'gamma': 0.6666666666666666,\n",
       "   'learning_rate': 0.09000000000000001,\n",
       "   'max_depth': 11,\n",
       "   'min_child_weight': 2,\n",
       "   'reg_alpha': 0.5555555555555556,\n",
       "   'reg_lambda': 0.67,\n",
       "   'subsample': 1.0},\n",
       "  {'colsample_bylevel': 0.8888888888888888,\n",
       "   'colsample_bytree': 0.7222222222222222,\n",
       "   'gamma': 0.5555555555555556,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 16,\n",
       "   'min_child_weight': 1,\n",
       "   'reg_alpha': 0.2222222222222222,\n",
       "   'reg_lambda': 0.78,\n",
       "   'subsample': 0.1},\n",
       "  {'colsample_bylevel': 0.9444444444444444,\n",
       "   'colsample_bytree': 0.8888888888888888,\n",
       "   'gamma': 1.0,\n",
       "   'learning_rate': 0.04000000000000001,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 4,\n",
       "   'reg_alpha': 0.2222222222222222,\n",
       "   'reg_lambda': 1.0,\n",
       "   'subsample': 1.0},\n",
       "  {'colsample_bylevel': 0.8333333333333333,\n",
       "   'colsample_bytree': 1.0,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.030000000000000006,\n",
       "   'max_depth': 21,\n",
       "   'min_child_weight': 1,\n",
       "   'reg_alpha': 0.0,\n",
       "   'reg_lambda': 0.12,\n",
       "   'subsample': 0.4},\n",
       "  {'colsample_bylevel': 0.7222222222222222,\n",
       "   'colsample_bytree': 0.6111111111111112,\n",
       "   'gamma': 1.0,\n",
       "   'learning_rate': 0.09000000000000001,\n",
       "   'max_depth': 16,\n",
       "   'min_child_weight': 4,\n",
       "   'reg_alpha': 1.0,\n",
       "   'reg_lambda': 0.56,\n",
       "   'subsample': 1.0},\n",
       "  {'colsample_bylevel': 0.5555555555555556,\n",
       "   'colsample_bytree': 0.9444444444444444,\n",
       "   'gamma': 0.7777777777777777,\n",
       "   'learning_rate': 0.09000000000000001,\n",
       "   'max_depth': 11,\n",
       "   'min_child_weight': 7,\n",
       "   'reg_alpha': 0.5555555555555556,\n",
       "   'reg_lambda': 1.0,\n",
       "   'subsample': 0.2},\n",
       "  {'colsample_bylevel': 0.5555555555555556,\n",
       "   'colsample_bytree': 0.7777777777777778,\n",
       "   'gamma': 0.7777777777777777,\n",
       "   'learning_rate': 0.08,\n",
       "   'max_depth': 1,\n",
       "   'min_child_weight': 6,\n",
       "   'reg_alpha': 0.8888888888888888,\n",
       "   'reg_lambda': 0.12,\n",
       "   'subsample': 0.1},\n",
       "  {'colsample_bylevel': 0.7222222222222222,\n",
       "   'colsample_bytree': 0.6666666666666666,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 26,\n",
       "   'min_child_weight': 9,\n",
       "   'reg_alpha': 1.0,\n",
       "   'reg_lambda': 0.45,\n",
       "   'subsample': 0.7000000000000001},\n",
       "  {'colsample_bylevel': 0.6111111111111112,\n",
       "   'colsample_bytree': 0.5,\n",
       "   'gamma': 0.5555555555555556,\n",
       "   'learning_rate': 0.09000000000000001,\n",
       "   'max_depth': 26,\n",
       "   'min_child_weight': 1,\n",
       "   'reg_alpha': 0.7777777777777777,\n",
       "   'reg_lambda': 0.56,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bylevel': 0.6111111111111112,\n",
       "   'colsample_bytree': 0.8888888888888888,\n",
       "   'gamma': 0.8888888888888888,\n",
       "   'learning_rate': 0.05000000000000001,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 2,\n",
       "   'reg_alpha': 0.6666666666666666,\n",
       "   'reg_lambda': 1.0,\n",
       "   'subsample': 1.0},\n",
       "  {'colsample_bylevel': 0.9444444444444444,\n",
       "   'colsample_bytree': 0.7777777777777778,\n",
       "   'gamma': 1.0,\n",
       "   'learning_rate': 0.06000000000000001,\n",
       "   'max_depth': 16,\n",
       "   'min_child_weight': 5,\n",
       "   'reg_alpha': 0.1111111111111111,\n",
       "   'reg_lambda': 0.34,\n",
       "   'subsample': 0.4},\n",
       "  {'colsample_bylevel': 0.7222222222222222,\n",
       "   'colsample_bytree': 1.0,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.07,\n",
       "   'max_depth': 26,\n",
       "   'min_child_weight': 1,\n",
       "   'reg_alpha': 0.7777777777777777,\n",
       "   'reg_lambda': 0.01,\n",
       "   'subsample': 0.7000000000000001},\n",
       "  {'colsample_bylevel': 0.9444444444444444,\n",
       "   'colsample_bytree': 0.7777777777777778,\n",
       "   'gamma': 0.7777777777777777,\n",
       "   'learning_rate': 0.020000000000000004,\n",
       "   'max_depth': 21,\n",
       "   'min_child_weight': 4,\n",
       "   'reg_alpha': 0.3333333333333333,\n",
       "   'reg_lambda': 1.0,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bylevel': 0.5555555555555556,\n",
       "   'colsample_bytree': 0.8888888888888888,\n",
       "   'gamma': 0.1111111111111111,\n",
       "   'learning_rate': 0.05000000000000001,\n",
       "   'max_depth': 1,\n",
       "   'min_child_weight': 5,\n",
       "   'reg_alpha': 0.2222222222222222,\n",
       "   'reg_lambda': 0.45,\n",
       "   'subsample': 0.4},\n",
       "  {'colsample_bylevel': 1.0,\n",
       "   'colsample_bytree': 0.7777777777777778,\n",
       "   'gamma': 0.5555555555555556,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 1,\n",
       "   'min_child_weight': 2,\n",
       "   'reg_alpha': 0.2222222222222222,\n",
       "   'reg_lambda': 0.23,\n",
       "   'subsample': 0.1},\n",
       "  {'colsample_bylevel': 0.7222222222222222,\n",
       "   'colsample_bytree': 0.8888888888888888,\n",
       "   'gamma': 0.7777777777777777,\n",
       "   'learning_rate': 0.07,\n",
       "   'max_depth': 11,\n",
       "   'min_child_weight': 1,\n",
       "   'reg_alpha': 0.2222222222222222,\n",
       "   'reg_lambda': 0.45,\n",
       "   'subsample': 0.4},\n",
       "  {'colsample_bylevel': 0.7222222222222222,\n",
       "   'colsample_bytree': 0.8333333333333333,\n",
       "   'gamma': 1.0,\n",
       "   'learning_rate': 0.09000000000000001,\n",
       "   'max_depth': 11,\n",
       "   'min_child_weight': 3,\n",
       "   'reg_alpha': 0.7777777777777777,\n",
       "   'reg_lambda': 0.23,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bylevel': 0.6111111111111112,\n",
       "   'colsample_bytree': 0.8888888888888888,\n",
       "   'gamma': 0.3333333333333333,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 11,\n",
       "   'min_child_weight': 4,\n",
       "   'reg_alpha': 0.4444444444444444,\n",
       "   'reg_lambda': 0.45,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bylevel': 0.7777777777777778,\n",
       "   'colsample_bytree': 0.6111111111111112,\n",
       "   'gamma': 0.5555555555555556,\n",
       "   'learning_rate': 0.09000000000000001,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 7,\n",
       "   'reg_alpha': 0.6666666666666666,\n",
       "   'reg_lambda': 0.67,\n",
       "   'subsample': 0.1},\n",
       "  {'colsample_bylevel': 0.6666666666666666,\n",
       "   'colsample_bytree': 0.8333333333333333,\n",
       "   'gamma': 1.0,\n",
       "   'learning_rate': 0.030000000000000006,\n",
       "   'max_depth': 1,\n",
       "   'min_child_weight': 4,\n",
       "   'reg_alpha': 0.3333333333333333,\n",
       "   'reg_lambda': 0.45,\n",
       "   'subsample': 0.30000000000000004},\n",
       "  {'colsample_bylevel': 0.9444444444444444,\n",
       "   'colsample_bytree': 0.6111111111111112,\n",
       "   'gamma': 0.5555555555555556,\n",
       "   'learning_rate': 0.09000000000000001,\n",
       "   'max_depth': 11,\n",
       "   'min_child_weight': 1,\n",
       "   'reg_alpha': 1.0,\n",
       "   'reg_lambda': 0.78,\n",
       "   'subsample': 0.30000000000000004},\n",
       "  {'colsample_bylevel': 0.6111111111111112,\n",
       "   'colsample_bytree': 0.8333333333333333,\n",
       "   'gamma': 0.2222222222222222,\n",
       "   'learning_rate': 0.04000000000000001,\n",
       "   'max_depth': 1,\n",
       "   'min_child_weight': 7,\n",
       "   'reg_alpha': 0.6666666666666666,\n",
       "   'reg_lambda': 0.89,\n",
       "   'subsample': 0.2},\n",
       "  {'colsample_bylevel': 0.6111111111111112,\n",
       "   'colsample_bytree': 0.8888888888888888,\n",
       "   'gamma': 0.1111111111111111,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 26,\n",
       "   'min_child_weight': 7,\n",
       "   'reg_alpha': 0.5555555555555556,\n",
       "   'reg_lambda': 0.23,\n",
       "   'subsample': 0.5},\n",
       "  {'colsample_bylevel': 0.9444444444444444,\n",
       "   'colsample_bytree': 0.5,\n",
       "   'gamma': 0.2222222222222222,\n",
       "   'learning_rate': 0.04000000000000001,\n",
       "   'max_depth': 21,\n",
       "   'min_child_weight': 8,\n",
       "   'reg_alpha': 0.4444444444444444,\n",
       "   'reg_lambda': 0.45,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bylevel': 0.9444444444444444,\n",
       "   'colsample_bytree': 0.5,\n",
       "   'gamma': 0.2222222222222222,\n",
       "   'learning_rate': 0.06000000000000001,\n",
       "   'max_depth': 1,\n",
       "   'min_child_weight': 3,\n",
       "   'reg_alpha': 0.2222222222222222,\n",
       "   'reg_lambda': 0.34,\n",
       "   'subsample': 0.30000000000000004},\n",
       "  {'colsample_bylevel': 0.6111111111111112,\n",
       "   'colsample_bytree': 0.6111111111111112,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.06000000000000001,\n",
       "   'max_depth': 1,\n",
       "   'min_child_weight': 6,\n",
       "   'reg_alpha': 0.3333333333333333,\n",
       "   'reg_lambda': 1.0,\n",
       "   'subsample': 0.2},\n",
       "  {'colsample_bylevel': 0.6111111111111112,\n",
       "   'colsample_bytree': 0.5555555555555556,\n",
       "   'gamma': 0.7777777777777777,\n",
       "   'learning_rate': 0.04000000000000001,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 4,\n",
       "   'reg_alpha': 0.8888888888888888,\n",
       "   'reg_lambda': 0.45,\n",
       "   'subsample': 0.2},\n",
       "  {'colsample_bylevel': 1.0,\n",
       "   'colsample_bytree': 0.6666666666666666,\n",
       "   'gamma': 0.5555555555555556,\n",
       "   'learning_rate': 0.09000000000000001,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 1,\n",
       "   'reg_alpha': 0.2222222222222222,\n",
       "   'reg_lambda': 0.12,\n",
       "   'subsample': 0.1},\n",
       "  {'colsample_bylevel': 0.6666666666666666,\n",
       "   'colsample_bytree': 1.0,\n",
       "   'gamma': 1.0,\n",
       "   'learning_rate': 0.06000000000000001,\n",
       "   'max_depth': 16,\n",
       "   'min_child_weight': 2,\n",
       "   'reg_alpha': 0.4444444444444444,\n",
       "   'reg_lambda': 0.45,\n",
       "   'subsample': 0.2},\n",
       "  {'colsample_bylevel': 0.6666666666666666,\n",
       "   'colsample_bytree': 0.5,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.09000000000000001,\n",
       "   'max_depth': 16,\n",
       "   'min_child_weight': 5,\n",
       "   'reg_alpha': 0.2222222222222222,\n",
       "   'reg_lambda': 0.23,\n",
       "   'subsample': 0.1},\n",
       "  {'colsample_bylevel': 1.0,\n",
       "   'colsample_bytree': 0.6666666666666666,\n",
       "   'gamma': 0.3333333333333333,\n",
       "   'learning_rate': 0.06000000000000001,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 9,\n",
       "   'reg_alpha': 0.4444444444444444,\n",
       "   'reg_lambda': 0.89,\n",
       "   'subsample': 0.7000000000000001}),\n",
       " 'rank_test_score': array([35, 22, 17, 32, 26, 48, 29,  9,  6, 31,  8, 28,  4, 18, 33, 30, 27,\n",
       "         1, 13,  3, 50, 11, 41,  2, 25, 34, 46, 23,  5, 15, 38, 44, 39, 49,\n",
       "        14, 10, 45, 20, 42, 19, 40, 47, 12, 36, 37, 16, 24, 21, 43,  7]),\n",
       " 'split0_test_score': array([-0.23586357, -0.23319744, -0.23068208, -0.24910121, -0.23567883,\n",
       "        -0.803689  , -0.24884199, -0.22985867, -0.22804281, -0.23813782,\n",
       "        -0.22874556, -0.23745047, -0.22873201, -0.2360864 , -0.24420956,\n",
       "        -0.24960214, -0.24889187, -0.22772301, -0.23497262, -0.22750331,\n",
       "        -0.81422135, -0.23225738, -0.2589038 , -0.22733108, -0.2345163 ,\n",
       "        -0.23596847, -0.79754639, -0.23384334, -0.22852199, -0.23082575,\n",
       "        -0.24392398, -0.32914948, -0.23909007, -0.80426427, -0.23078803,\n",
       "        -0.22994852, -0.79649045, -0.23175502, -0.26081334, -0.23271681,\n",
       "        -0.24400138, -0.80040847, -0.23402499, -0.23729791, -0.23745676,\n",
       "        -0.2343633 , -0.23393746, -0.23336763, -0.26272242, -0.22767548]),\n",
       " 'split0_train_score': array([-0.22793009, -0.10700009, -0.13172439, -0.21253316, -0.12127871,\n",
       "        -0.67846562, -0.13465133, -0.15012566, -0.11705551, -0.1477189 ,\n",
       "        -0.16223216, -0.16710544, -0.15246971, -0.11431975, -0.1243622 ,\n",
       "        -0.1325342 , -0.16940651, -0.12329357, -0.1159404 , -0.14646089,\n",
       "        -0.70457844, -0.20886281, -0.06672239, -0.151146  , -0.1804745 ,\n",
       "        -0.22718526, -0.6912074 , -0.10025124, -0.20660851, -0.14283179,\n",
       "        -0.02655942, -0.23955374, -0.23053423, -0.71409585, -0.15824319,\n",
       "        -0.1632133 , -0.68503076, -0.2106162 , -0.24263424, -0.16594854,\n",
       "        -0.23282161, -0.68174937, -0.11635497, -0.22904805, -0.22912278,\n",
       "        -0.21617443, -0.20901175, -0.16849472, -0.16430541, -0.204146  ]),\n",
       " 'split1_test_score': array([-0.22381762, -0.21798851, -0.21556038, -0.23046936, -0.21967504,\n",
       "        -0.77904043, -0.22900828, -0.2151828 , -0.21338678, -0.22146219,\n",
       "        -0.21355555, -0.22086728, -0.21247203, -0.21857349, -0.22547374,\n",
       "        -0.22901706, -0.22851993, -0.21277215, -0.21726548, -0.21284069,\n",
       "        -0.78789495, -0.2177522 , -0.23764885, -0.21241046, -0.21895461,\n",
       "        -0.22307299, -0.77643962, -0.21767149, -0.2146017 , -0.21582544,\n",
       "        -0.22509538, -0.30218118, -0.22767776, -0.80619353, -0.21499359,\n",
       "        -0.2136164 , -0.77299491, -0.21828122, -0.24990333, -0.21753399,\n",
       "        -0.23267632, -0.77547085, -0.21711146, -0.22522902, -0.22550278,\n",
       "        -0.21930813, -0.2177901 , -0.2183404 , -0.23899956, -0.21390761]),\n",
       " 'split1_train_score': array([-0.23379184, -0.10459952, -0.13478462, -0.21777241, -0.12113904,\n",
       "        -0.67480532, -0.13284419, -0.1484067 , -0.11642722, -0.14894271,\n",
       "        -0.1641613 , -0.16854487, -0.15307165, -0.11395905, -0.1249052 ,\n",
       "        -0.13494873, -0.17118258, -0.1196366 , -0.11398565, -0.14960924,\n",
       "        -0.70167739, -0.21430671, -0.06601377, -0.14972334, -0.1822707 ,\n",
       "        -0.23296716, -0.68820627, -0.09710243, -0.2122876 , -0.14227064,\n",
       "        -0.02425867, -0.23992016, -0.2359308 , -0.71082423, -0.15892642,\n",
       "        -0.16596659, -0.68195215, -0.21654359, -0.2474793 , -0.17117882,\n",
       "        -0.23799474, -0.67799505, -0.11468598, -0.23474798, -0.23482529,\n",
       "        -0.22175984, -0.21484088, -0.17171621, -0.16608408, -0.2096126 ]),\n",
       " 'split2_test_score': array([-0.25174039, -0.24472077, -0.24322318, -0.22894795, -0.24823106,\n",
       "        -0.57449399, -0.22864641, -0.23829786, -0.239487  , -0.24891194,\n",
       "        -0.23996343, -0.24765532, -0.23837203, -0.23564632, -0.23925067,\n",
       "        -0.22927903, -0.22811985, -0.2379664 , -0.23329234, -0.23920538,\n",
       "        -0.58012761, -0.23421068, -0.23424706, -0.2395414 , -0.24678254,\n",
       "        -0.25099313, -0.56678147, -0.2447692 , -0.23772493, -0.24128696,\n",
       "        -0.24815027, -0.25107448, -0.25148566, -0.56747277, -0.24209381,\n",
       "        -0.24060895, -0.5696818 , -0.24533826, -0.24095258, -0.24493436,\n",
       "        -0.24806702, -0.57337505, -0.23336665, -0.25232031, -0.25238315,\n",
       "        -0.23552834, -0.24694093, -0.24411417, -0.27162146, -0.23938367]),\n",
       " 'split2_train_score': array([-0.22321482, -0.10408657, -0.13012409, -0.20968566, -0.11742074,\n",
       "        -0.7144258 , -0.1333132 , -0.14636818, -0.11559563, -0.14747684,\n",
       "        -0.15863194, -0.16451168, -0.14997507, -0.11162498, -0.12265789,\n",
       "        -0.13229322, -0.16676481, -0.12198734, -0.11437332, -0.14428262,\n",
       "        -0.73869969, -0.2045432 , -0.06771236, -0.14501606, -0.17759526,\n",
       "        -0.22286621, -0.72538178, -0.09701109, -0.20224821, -0.14011397,\n",
       "        -0.02632838, -0.24138068, -0.22580585, -0.74806933, -0.15613518,\n",
       "        -0.16043559, -0.71880778, -0.20704989, -0.23847769, -0.16421577,\n",
       "        -0.22827991, -0.7166397 , -0.11618081, -0.22446785, -0.22474652,\n",
       "        -0.21174101, -0.20497463, -0.16642588, -0.16135863, -0.20031988]),\n",
       " 'std_fit_time': array([  9.56966669e-02,   5.81110671e-01,   4.81549323e-01,\n",
       "          2.98984866e-01,   5.21588227e-01,   1.39021550e+00,\n",
       "          1.74152055e+00,   3.36964128e-01,   3.61164565e-01,\n",
       "          1.32878500e-01,   9.28242370e-01,   1.36743214e+00,\n",
       "          3.08545543e-01,   7.93857382e-01,   2.35018968e-01,\n",
       "          2.19945661e+00,   4.05844797e+00,   5.44831338e-01,\n",
       "          1.29211227e+00,   1.97456267e-01,   4.71100069e-01,\n",
       "          8.70551598e-01,   2.93010144e-01,   3.70688378e-01,\n",
       "          2.26235830e-01,   3.76328797e-02,   4.18044030e-01,\n",
       "          2.25510975e-01,   2.07251703e-01,   6.25722449e-01,\n",
       "          2.77663249e+00,   7.20718758e-02,   8.59827102e-02,\n",
       "          3.59741598e-02,   1.27983267e-01,   2.00110295e-01,\n",
       "          1.32945451e-01,   3.72729888e-02,   8.53117280e-03,\n",
       "          4.33040255e-02,   4.71072428e-03,   3.89252812e-01,\n",
       "          5.71448252e-01,   5.51840115e-03,   1.98803894e-03,\n",
       "          1.94345976e-02,   4.55521868e-02,   7.90345937e-02,\n",
       "          2.44301103e-01,   1.22774975e-01]),\n",
       " 'std_score_time': array([  1.74757444e-02,   4.96439892e-02,   4.78805828e-02,\n",
       "          4.14431365e-02,   2.24419305e-02,   6.38735599e-02,\n",
       "          6.10177056e-02,   1.85546310e-02,   6.87972676e-03,\n",
       "          1.02229608e-02,   4.46986175e-02,   3.67876038e-02,\n",
       "          1.41495839e-02,   1.73391587e-01,   6.16335382e-02,\n",
       "          1.23963829e-01,   9.70272249e-02,   5.95835240e-02,\n",
       "          5.01882974e-02,   5.20448700e-03,   1.43984831e-02,\n",
       "          7.22616148e-03,   1.05044250e-01,   5.27003031e-03,\n",
       "          2.49872685e-03,   1.24853071e-03,   9.54058363e-03,\n",
       "          1.04938644e-01,   1.11731038e-03,   1.29311730e-02,\n",
       "          3.15310807e-02,   2.12322150e-02,   6.00506125e-03,\n",
       "          2.98286309e-03,   4.74888615e-02,   3.98619729e-02,\n",
       "          5.15042996e-07,   8.05950936e-03,   1.56139395e-06,\n",
       "          6.25769923e-07,   7.36693196e-03,   6.25769923e-07,\n",
       "          1.09379667e-02,   2.64299538e-06,   6.10537799e-05,\n",
       "          7.44080309e-03,   7.05897009e-03,   8.97923724e-03,\n",
       "          8.22036186e-03,   6.40896414e-03]),\n",
       " 'std_test_score': array([ 0.01143513,  0.01094792,  0.01130966,  0.00916281,  0.0116863 ,\n",
       "         0.10272788,  0.00943615,  0.00955049,  0.01068223,  0.01129231,\n",
       "         0.01082155,  0.01103902,  0.01068814,  0.00815392,  0.00792622,\n",
       "         0.00964274,  0.0096991 ,  0.01034518,  0.00798072,  0.01078594,\n",
       "         0.10470075,  0.00734164,  0.01091024,  0.01109457,  0.01138723,\n",
       "         0.01140939,  0.10416573,  0.01113148,  0.00950527,  0.01044954,\n",
       "         0.01002168,  0.03237779,  0.0097223 ,  0.11208208,  0.01111409,\n",
       "         0.01110046,  0.10183343,  0.01104602,  0.00812126,  0.01120797,\n",
       "         0.00651204,  0.1016578 ,  0.00782256,  0.01108186,  0.01099621,\n",
       "         0.00738701,  0.01192382,  0.01057036,  0.01376855,  0.01041188]),\n",
       " 'std_train_score': array([ 0.0043265 ,  0.00126993,  0.00193352,  0.00334919,  0.00178665,\n",
       "         0.01787709,  0.00076567,  0.00153583,  0.00059792,  0.00064162,\n",
       "         0.00229146,  0.00166887,  0.00134058,  0.00119442,  0.00095742,\n",
       "         0.00119906,  0.00181505,  0.00151312,  0.00084506,  0.00218657,\n",
       "         0.01681047,  0.00399473,  0.00069661,  0.00261956,  0.00192574,\n",
       "         0.00413808,  0.0168619 ,  0.00150636,  0.00411033,  0.00117154,\n",
       "         0.00103444,  0.00078917,  0.00413649,  0.01683943,  0.00118797,\n",
       "         0.00225803,  0.01669565,  0.00391554,  0.00367847,  0.00295978,\n",
       "         0.00396885,  0.0174    ,  0.0007491 ,  0.00420514,  0.0041265 ,\n",
       "         0.00409917,  0.00404996,  0.00217679,  0.0019487 ,  0.00381339])}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# specify parameters and distributions to sample from\n",
    "clf = xgb.XGBRegressor()\n",
    "params = {\n",
    "            'learning_rate': np.linspace(0.01,0.1,10).tolist(),\n",
    "            'gamma': np.linspace(0.0,1.0,10).tolist(),\n",
    "            'max_depth': np.arange(1,31,5).tolist(),\n",
    "            'min_child_weight':np.arange(1,10,1).tolist(),\n",
    "            'subsample':np.linspace(0.1,1.0,10).tolist(),\n",
    "            'colsample_bytree':np.linspace(0.5,1.0,10).tolist(),\n",
    "            'colsample_bylevel':np.linspace(0.5,1.0,10).tolist(),\n",
    "            'reg_lambda': np.linspace(0.01,1.0,10).tolist(),\n",
    "            'reg_alpha': np.linspace(0.0,1.0,10).tolist()\n",
    "          }\n",
    "\n",
    "k_fold = KFold(3, random_state=1)\n",
    "\n",
    "grid_search = RandomizedSearchCV(clf, param_distributions=params,scoring='neg_mean_squared_error', cv=k_fold, n_iter=50)\n",
    "grid_search.fit(x_train, y_train)\n",
    "result = grid_search.cv_results_\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "optimized_list = []\n",
    "optimized = {}\n",
    "\n",
    "#take the best CV result\n",
    "for i in range(1,51):\n",
    "    best = np.flatnonzero(result['rank_test_score'] == i)\n",
    "    for b in best:\n",
    "        rmse = np.sqrt(abs(result['mean_test_score'][b]))\n",
    "        optimized = {'rank': i, 'rmse': rmse,\n",
    "                     'gamma': result['param_gamma'].data[b],\n",
    "                     'learning_rate': result['param_learning_rate'].data[b],\n",
    "                     'reg_lambda': result['param_reg_lambda'].data[b],\n",
    "                     'reg_alpha': result['param_reg_alpha'].data[b],\n",
    "                     'max_depth': result['param_max_depth'].data[b],\n",
    "                     'colsample_bytree': result['param_colsample_bytree'].data[b],\n",
    "                     'colsample_bylevel': result['param_colsample_bylevel'].data[b],\n",
    "                     'subsample': result['param_subsample'].data[b],\n",
    "                     'min_child_weight': result['param_min_child_weight'].data[b]}        \n",
    "        optimized_list.append(optimized)\n",
    "#optimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>rmse</th>\n",
       "      <th>gamma</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>reg_lambda</th>\n",
       "      <th>reg_alpha</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>colsample_bytree</th>\n",
       "      <th>colsample_bylevel</th>\n",
       "      <th>subsample</th>\n",
       "      <th>min_child_weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.475556</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.475844</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.475937</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.475947</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.78</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.7</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.476392</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.476416</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.476434</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.476887</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.477263</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.477554</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.6</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.477570</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.04</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.0</td>\n",
       "      <td>0.477669</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.6</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.0</td>\n",
       "      <td>0.478027</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.0</td>\n",
       "      <td>0.478844</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.0</td>\n",
       "      <td>0.478866</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.0</td>\n",
       "      <td>0.479305</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.0</td>\n",
       "      <td>0.479397</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.09</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.0</td>\n",
       "      <td>0.479690</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.0</td>\n",
       "      <td>0.481382</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.78</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.481447</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.1</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.0</td>\n",
       "      <td>0.481602</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.0</td>\n",
       "      <td>0.481632</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23.0</td>\n",
       "      <td>0.481762</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24.0</td>\n",
       "      <td>0.482586</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25.0</td>\n",
       "      <td>0.483133</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.09</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.2</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26.0</td>\n",
       "      <td>0.484281</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27.0</td>\n",
       "      <td>0.484951</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28.0</td>\n",
       "      <td>0.485102</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29.0</td>\n",
       "      <td>0.485282</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.8</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30.0</td>\n",
       "      <td>0.485763</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31.0</td>\n",
       "      <td>0.485974</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.2</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32.0</td>\n",
       "      <td>0.485976</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33.0</td>\n",
       "      <td>0.486119</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>34.0</td>\n",
       "      <td>0.486496</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.1</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>35.0</td>\n",
       "      <td>0.486971</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.07</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>36.0</td>\n",
       "      <td>0.488142</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>37.0</td>\n",
       "      <td>0.488311</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.2</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>38.0</td>\n",
       "      <td>0.488934</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>39.0</td>\n",
       "      <td>0.489303</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>40.0</td>\n",
       "      <td>0.491509</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.2</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>41.0</td>\n",
       "      <td>0.493558</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>42.0</td>\n",
       "      <td>0.500556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.3</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>43.0</td>\n",
       "      <td>0.507722</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>44.0</td>\n",
       "      <td>0.542342</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>45.0</td>\n",
       "      <td>0.844426</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.6</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>46.0</td>\n",
       "      <td>0.844742</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.45</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.7</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>47.0</td>\n",
       "      <td>0.846415</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.5</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>48.0</td>\n",
       "      <td>0.847983</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>49.0</td>\n",
       "      <td>0.852043</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>50.0</td>\n",
       "      <td>0.852886</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rank      rmse     gamma  learning_rate  reg_lambda  reg_alpha  max_depth  \\\n",
       "0    1.0  0.475556  0.333333           0.06        0.56   0.888889       16.0   \n",
       "1    2.0  0.475844  1.000000           0.09        0.56   1.000000       16.0   \n",
       "2    3.0  0.475937  0.666667           0.09        0.67   0.555556       11.0   \n",
       "3    4.0  0.475947  0.000000           0.06        0.78   1.000000       11.0   \n",
       "4    5.0  0.476392  0.888889           0.05        1.00   0.666667        6.0   \n",
       "5    6.0  0.476416  0.444444           0.07        0.01   0.888889       16.0   \n",
       "6    7.0  0.476434  0.333333           0.06        0.89   0.444444        6.0   \n",
       "7    8.0  0.476887  0.666667           0.07        0.56   0.888889       11.0   \n",
       "8    9.0  0.477263  0.333333           0.05        0.56   0.888889       16.0   \n",
       "9   10.0  0.477554  1.000000           0.09        0.23   0.777778       11.0   \n",
       "10  11.0  0.477570  1.000000           0.04        1.00   0.222222        6.0   \n",
       "11  12.0  0.477669  0.222222           0.04        0.45   0.444444       21.0   \n",
       "12  13.0  0.478027  0.111111           0.04        0.01   0.666667       21.0   \n",
       "13  14.0  0.478844  0.777778           0.07        0.45   0.222222       11.0   \n",
       "14  15.0  0.478866  1.000000           0.06        0.34   0.111111       16.0   \n",
       "15  16.0  0.479305  0.777778           0.04        0.45   0.888889        6.0   \n",
       "16  17.0  0.479397  0.222222           0.09        1.00   0.666667       11.0   \n",
       "17  18.0  0.479690  0.888889           0.04        0.12   0.000000       26.0   \n",
       "18  19.0  0.481382  0.555556           0.09        0.78   1.000000       11.0   \n",
       "19  20.0  0.481447  0.555556           0.09        0.67   0.666667        6.0   \n",
       "20  21.0  0.481602  1.000000           0.06        0.45   0.444444       16.0   \n",
       "21  22.0  0.481632  0.111111           0.06        0.01   0.888889       21.0   \n",
       "22  23.0  0.481762  0.555556           0.09        0.56   0.777778       26.0   \n",
       "23  24.0  0.482586  0.555556           0.09        0.12   0.222222        6.0   \n",
       "24  25.0  0.483133  0.777778           0.09        1.00   0.555556       11.0   \n",
       "25  26.0  0.484281  0.000000           0.09        0.23   0.222222       11.0   \n",
       "26  27.0  0.484951  0.555556           0.03        0.78   0.777778       21.0   \n",
       "27  28.0  0.485102  0.888889           0.09        0.56   1.000000       21.0   \n",
       "28  29.0  0.485282  0.333333           0.03        0.12   0.777778       21.0   \n",
       "29  30.0  0.485763  0.222222           0.03        0.23   0.000000       16.0   \n",
       "30  31.0  0.485974  0.111111           0.07        0.89   0.555556       16.0   \n",
       "31  32.0  0.485976  1.000000           0.03        0.12   0.888889       11.0   \n",
       "32  33.0  0.486119  0.000000           0.04        0.89   0.000000       26.0   \n",
       "33  34.0  0.486496  0.777778           0.08        0.12   0.888889        1.0   \n",
       "34  35.0  0.486971  0.888889           0.07        1.00   0.666667        1.0   \n",
       "35  36.0  0.488142  0.222222           0.06        0.34   0.222222        1.0   \n",
       "36  37.0  0.488311  0.000000           0.06        1.00   0.333333        1.0   \n",
       "37  38.0  0.488934  0.000000           0.07        0.01   0.777778       26.0   \n",
       "38  39.0  0.489303  0.111111           0.05        0.45   0.222222        1.0   \n",
       "39  40.0  0.491509  0.222222           0.04        0.89   0.666667        1.0   \n",
       "40  41.0  0.493558  0.000000           0.03        0.12   0.000000       21.0   \n",
       "41  42.0  0.500556  1.000000           0.03        0.45   0.333333        1.0   \n",
       "42  43.0  0.507722  0.000000           0.09        0.23   0.222222       16.0   \n",
       "43  44.0  0.542342  0.777778           0.02        1.00   0.333333       21.0   \n",
       "44  45.0  0.844426  0.333333           0.01        0.45   0.444444       11.0   \n",
       "45  46.0  0.844742  0.000000           0.01        0.45   1.000000       26.0   \n",
       "46  47.0  0.846415  0.111111           0.01        0.23   0.555556       26.0   \n",
       "47  48.0  0.847983  0.111111           0.01        1.00   0.222222       26.0   \n",
       "48  49.0  0.852043  0.555556           0.01        0.23   0.222222        1.0   \n",
       "49  50.0  0.852886  0.555556           0.01        0.78   0.222222       16.0   \n",
       "\n",
       "    colsample_bytree  colsample_bylevel  subsample  min_child_weight  \n",
       "0           0.555556           0.555556        1.0               6.0  \n",
       "1           0.611111           0.722222        1.0               4.0  \n",
       "2           0.555556           0.722222        1.0               2.0  \n",
       "3           0.722222           0.944444        0.7               4.0  \n",
       "4           0.888889           0.611111        1.0               2.0  \n",
       "5           0.666667           0.666667        1.0               7.0  \n",
       "6           0.666667           1.000000        0.7               9.0  \n",
       "7           0.833333           0.722222        0.6               1.0  \n",
       "8           0.833333           0.555556        0.4               5.0  \n",
       "9           0.833333           0.722222        0.6               3.0  \n",
       "10          0.888889           0.944444        1.0               4.0  \n",
       "11          0.500000           0.944444        0.6               8.0  \n",
       "12          0.722222           0.500000        0.6               6.0  \n",
       "13          0.888889           0.722222        0.4               1.0  \n",
       "14          0.777778           0.944444        0.4               5.0  \n",
       "15          0.555556           0.611111        0.2               4.0  \n",
       "16          0.611111           1.000000        0.6               1.0  \n",
       "17          0.722222           0.555556        0.4               2.0  \n",
       "18          0.611111           0.944444        0.3               1.0  \n",
       "19          0.611111           0.777778        0.1               7.0  \n",
       "20          1.000000           0.666667        0.2               2.0  \n",
       "21          0.666667           1.000000        0.4               7.0  \n",
       "22          0.500000           0.611111        0.6               1.0  \n",
       "23          0.666667           1.000000        0.1               1.0  \n",
       "24          0.944444           0.555556        0.2               7.0  \n",
       "25          0.944444           1.000000        0.4               3.0  \n",
       "26          0.777778           0.666667        0.5               3.0  \n",
       "27          0.722222           0.611111        0.2               5.0  \n",
       "28          0.944444           0.666667        0.8               5.0  \n",
       "29          0.611111           0.722222        0.4               4.0  \n",
       "30          0.888889           0.833333        0.2               8.0  \n",
       "31          0.500000           0.777778        0.3               1.0  \n",
       "32          0.833333           0.777778        0.2               4.0  \n",
       "33          0.777778           0.555556        0.1               6.0  \n",
       "34          0.555556           0.777778        0.1               4.0  \n",
       "35          0.500000           0.944444        0.3               3.0  \n",
       "36          0.611111           0.611111        0.2               6.0  \n",
       "37          1.000000           0.722222        0.7               1.0  \n",
       "38          0.888889           0.555556        0.4               5.0  \n",
       "39          0.833333           0.611111        0.2               7.0  \n",
       "40          1.000000           0.833333        0.4               1.0  \n",
       "41          0.833333           0.666667        0.3               4.0  \n",
       "42          0.500000           0.666667        0.1               5.0  \n",
       "43          0.777778           0.944444        0.5               4.0  \n",
       "44          0.888889           0.611111        0.6               4.0  \n",
       "45          0.666667           0.722222        0.7               9.0  \n",
       "46          0.888889           0.611111        0.5               7.0  \n",
       "47          0.555556           1.000000        0.7               5.0  \n",
       "48          0.777778           1.000000        0.1               2.0  \n",
       "49          0.722222           0.888889        0.1               1.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=['rank','rmse','gamma','learning_rate','reg_lambda','reg_alpha','max_depth','colsample_bytree','colsample_bylevel','subsample','min_child_weight'])\n",
    "df = df.append(optimized_list)\n",
    "df.to_csv('optimisation_xgboost.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score = []\n",
    "def metric_scorer(model, x, y):\n",
    "    y_pred = model.predict(x)\n",
    "    exp_var = metrics.explained_variance_score(y,y_pred)\n",
    "    mean_abs_err = metrics.mean_absolute_error(y,y_pred)\n",
    "    mean_sq_err = metrics.mean_squared_error(y,y_pred)\n",
    "    rms = np.sqrt(mean_sq_err)\n",
    "    r2_sc = metrics.r2_score(y,y_pred)\n",
    "    score.append((exp_var,mean_abs_err,mean_sq_err,rms,r2_sc))\n",
    "    \n",
    "    return rms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gamma                 0.333333\n",
       "learning_rate         0.060000\n",
       "reg_lambda            0.560000\n",
       "reg_alpha             0.888889\n",
       "max_depth            16.000000\n",
       "colsample_bytree      0.555556\n",
       "colsample_bylevel     0.555556\n",
       "subsample             1.000000\n",
       "min_child_weight      6.000000\n",
       "Name: 0, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimum_param = df.iloc[0][2:]\n",
    "optimum_param = optimum_param.T\n",
    "optimum_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = xgb.XGBRegressor(gamma=optimum_param['gamma'],\n",
    "                         learning_rate=optimum_param['learning_rate'],\n",
    "                         reg_lambda=optimum_param['reg_lambda'],\n",
    "                         reg_alpha=optimum_param['reg_alpha'],\n",
    "                         max_depth=int(optimum_param['max_depth']),\n",
    "                         colsample_bytree=optimum_param['colsample_bytree'],\n",
    "                         colsample_bylevel=optimum_param['colsample_bylevel'],\n",
    "                         subsample=optimum_param['subsample'],\n",
    "                         min_child_weight=optimum_param['min_child_weight']\n",
    "                        )\n",
    "model.fit(x_train,y_train)\n",
    "y_pred= model.predict(x_test)\n",
    "#id_test = test.id\n",
    "pd.DataFrame({\"id\": id_test, \"relevance\": y_pred}).to_csv('submission_xgboost.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F- 1</th>\n",
       "      <th>F- 2</th>\n",
       "      <th>F- 3</th>\n",
       "      <th>F- 4</th>\n",
       "      <th>F- 5</th>\n",
       "      <th>F- 6</th>\n",
       "      <th>F- 7</th>\n",
       "      <th>F- 8</th>\n",
       "      <th>F- 9</th>\n",
       "      <th>F- 10</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>expl_var</th>\n",
       "      <td>0.205656</td>\n",
       "      <td>0.230447</td>\n",
       "      <td>0.241488</td>\n",
       "      <td>0.242358</td>\n",
       "      <td>0.226975</td>\n",
       "      <td>0.255400</td>\n",
       "      <td>0.235973</td>\n",
       "      <td>0.229167</td>\n",
       "      <td>0.172305</td>\n",
       "      <td>0.176172</td>\n",
       "      <td>0.221594</td>\n",
       "      <td>0.026623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mae</th>\n",
       "      <td>0.398054</td>\n",
       "      <td>0.380329</td>\n",
       "      <td>0.374238</td>\n",
       "      <td>0.373989</td>\n",
       "      <td>0.370209</td>\n",
       "      <td>0.367456</td>\n",
       "      <td>0.371775</td>\n",
       "      <td>0.373086</td>\n",
       "      <td>0.374401</td>\n",
       "      <td>0.386092</td>\n",
       "      <td>0.376963</td>\n",
       "      <td>0.008604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mse</th>\n",
       "      <td>0.235486</td>\n",
       "      <td>0.220477</td>\n",
       "      <td>0.212049</td>\n",
       "      <td>0.213976</td>\n",
       "      <td>0.210358</td>\n",
       "      <td>0.206253</td>\n",
       "      <td>0.210653</td>\n",
       "      <td>0.219212</td>\n",
       "      <td>0.222379</td>\n",
       "      <td>0.236383</td>\n",
       "      <td>0.218723</td>\n",
       "      <td>0.009835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rmse</th>\n",
       "      <td>0.485269</td>\n",
       "      <td>0.469550</td>\n",
       "      <td>0.460487</td>\n",
       "      <td>0.462576</td>\n",
       "      <td>0.458649</td>\n",
       "      <td>0.454151</td>\n",
       "      <td>0.458969</td>\n",
       "      <td>0.468200</td>\n",
       "      <td>0.471571</td>\n",
       "      <td>0.486192</td>\n",
       "      <td>0.467561</td>\n",
       "      <td>0.010436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r2</th>\n",
       "      <td>0.186035</td>\n",
       "      <td>0.221007</td>\n",
       "      <td>0.235171</td>\n",
       "      <td>0.238805</td>\n",
       "      <td>0.223602</td>\n",
       "      <td>0.254048</td>\n",
       "      <td>0.233477</td>\n",
       "      <td>0.218843</td>\n",
       "      <td>0.151351</td>\n",
       "      <td>0.152708</td>\n",
       "      <td>0.211505</td>\n",
       "      <td>0.034077</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              F- 1      F- 2      F- 3      F- 4      F- 5      F- 6  \\\n",
       "expl_var  0.205656  0.230447  0.241488  0.242358  0.226975  0.255400   \n",
       "mae       0.398054  0.380329  0.374238  0.373989  0.370209  0.367456   \n",
       "mse       0.235486  0.220477  0.212049  0.213976  0.210358  0.206253   \n",
       "rmse      0.485269  0.469550  0.460487  0.462576  0.458649  0.454151   \n",
       "r2        0.186035  0.221007  0.235171  0.238805  0.223602  0.254048   \n",
       "\n",
       "              F- 7      F- 8      F- 9     F- 10      mean       std  \n",
       "expl_var  0.235973  0.229167  0.172305  0.176172  0.221594  0.026623  \n",
       "mae       0.371775  0.373086  0.374401  0.386092  0.376963  0.008604  \n",
       "mse       0.210653  0.219212  0.222379  0.236383  0.218723  0.009835  \n",
       "rmse      0.458969  0.468200  0.471571  0.486192  0.467561  0.010436  \n",
       "r2        0.233477  0.218843  0.151351  0.152708  0.211505  0.034077  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_fold = KFold(10, random_state=1)\n",
    "xbg_scores = cross_val_score(model, x_train, y_train, cv=k_fold, scoring=metric_scorer, n_jobs=1)\n",
    "\n",
    "# In[6]:\n",
    "\n",
    "# CV results\n",
    "cv_results_df = pd.DataFrame(score)\n",
    "cv_results_df.columns = ['expl_var','mae','mse','rmse','r2']\n",
    "cv_results_df = cv_results_df.T\n",
    "cv_results_df.columns = ['F- '+str(i+1) for i in cv_results_df.columns]\n",
    "means = []\n",
    "stds = []\n",
    "for i in range(0,5):\n",
    "    means.append(np.mean(cv_results_df.iloc[i].values))\n",
    "    stds.append(np.std(cv_results_df.iloc[i].values))\n",
    "cv_results_df['mean'] = means\n",
    "cv_results_df['std'] = stds\n",
    "cv_results_df.to_csv('CV_xgboost.csv')\n",
    "cv_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
